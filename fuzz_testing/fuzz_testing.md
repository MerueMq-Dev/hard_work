# Фазз тестирование проекта AutoTrack

## Общая информация о проекте
Язык программирования: C# (.NET 8)
База данных: PostgreSQL, Entity Framework
Размер проекта: 9800 строк кода
Описание: AutoTrack — серверное приложение для управления автопарком предприятия, включающее учёт транспортных средств, водителей, поездок и телеметрии

## Применённые инструменты фазз-тестирования

#### SharpFuzz для модульного тестирования
Использовал SharpFuzz — инструмент для фазз-тестирования .NET кода на основе AFL (American Fuzzy Lop). Создал фазз-тесты для критических компонентов обработки данных: парсера телеметрии, валидатора входных данных и десериализатора маршрутов. SharpFuzz генерировал случайные входные данные в формате byte[], которые передавались в тестируемые методы через Fuzzer.Run().

#### Schemathesis для тестирования Web API
Применил Schemathesis для автоматического тестирования REST API на основе OpenAPI-спецификации проекта. Инструмент автоматически сгенерировал тысячи HTTP-запросов ко всем endpoints с различными комбинациями параметров, включая граничные значения, специальные символы и некорректные форматы данных.

### Выявленные ошибки
Обнаружил 5 критических ошибок:
- NullReferenceException в парсере телеметрии при обработке пустых GPS-координат
- Необработанное исключение при десериализации JSON с нестандартными escape-последовательностями
- 500 Internal Server Error на endpoint создания поездки при передаче отрицательного пробега
- Падение приложения при обработке строк длиной более 10000 символов в описании маршрута
- Некорректная валидация дат — принимались даты из будущего для завершённых поездок


## Трудности при организации фазз-тестирования

Основной сложностью стала настройка инструментации SharpFuzz для проекта с чистой архитектурой. Пришлось инструментировать не только основную сборку, но и отдельные модули Domain и Application. Также было непросто понять, границ между "ожидаемыми" и "критическими" исключениями — потребовалось детально продумать, какие исключения должны корректно обрабатываться, а какие указывают на реальные баги.

При работе с Schemathesis выяснилось, что в OpenAPI-спецификации не хватало подробного описания правил валидации. Из-за этого инструмент не мог генерировать самые эффективные тестовые данные. Пришлось дополнить swagger-описание правилами из FluentValidation.

Ещё одна неожиданная проблема — разбор результатов. Инструменты создавали тысячи тестовых случаев, и нужно было отделить реальные ошибки от нормального поведения программы. Например, многие ответы 400 Bad Request были правильными, но среди них терялись действительно проблемные случаи.

## Процесс исправления
После нахождения ошибок добавил проверку входных данных через FluentValidation: ограничения на длину строк, допустимые диапазоны чисел и форматы дат. Улучшил обработку ошибок — теперь вместо падения сервера (500) возвращается понятная ошибка (400 Bad Request) без раскрытия внутреннего устройства. Добавил явные проверки на пустые значения и граничные случаи в важных местах кода.

## Выводы
Фазз-тестирование оказалось очень полезным дополнением к обычным тестам, особенно для программы, которая обрабатывает данные извне. Больше всего удивило, как фаззер находит ситуации, о которых просто не подумаешь при написании тестов вручную. Например, кто будет специально проверять, что случится, если ввести строку из 10000 символов в поле описания? Понял, что хорошее описание API в OpenAPI важно не только для документации, но и для автоматического тестирования.

**Главный вывод**: человек плохо угадывает, как программа поведёт себя на странных данных — автоматика справляется с этим намного лучше.